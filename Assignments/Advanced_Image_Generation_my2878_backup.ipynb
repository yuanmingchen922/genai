{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1913f38",
   "metadata": {},
   "source": [
    "# Assignment 4: Advanced Image Generation\n",
    "## Diffusion Models and Energy-Based Models\n",
    "\n",
    "**Student**: my2878  \n",
    "**Course**: Generative AI  \n",
    "**Date**: November 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements two advanced generative models:\n",
    "\n",
    "1. **Diffusion Model (DDPM)** - Denoising Diffusion Probabilistic Model\n",
    "2. **Energy-Based Model (EBM)** - Using Langevin Dynamics\n",
    "\n",
    "Both models are trained on **CIFAR-10** dataset and integrated into the FastAPI.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Part 1: Diffusion Model Implementation](#diffusion)\n",
    "3. [Part 2: Energy-Based Model Implementation](#energy)\n",
    "4. [Part 3: Training on CIFAR-10](#training)\n",
    "5. [Part 4: Theory Questions](#theory)\n",
    "6. [Part 5: Results and Visualization](#results)\n",
    "7. [Part 6: API Integration](#api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674603e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \n",
    "                     'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba07b30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Part 1: Diffusion Model Implementation\n",
    "\n",
    "### 2.1 Sinusoidal Time Embedding\n",
    "\n",
    "The sinusoidal time embedding provides a continuous representation of timesteps using sine and cosine functions.\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "For timestep $t$ and embedding dimension $d$, the $i$-th dimension is:\n",
    "\n",
    "$$\n",
    "\\text{embedding}[2i] = \\sin\\left(\\frac{t}{10000^{2i/d}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{embedding}[2i+1] = \\cos\\left(\\frac{t}{10000^{2i/d}}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab34c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Sinusoidal Time Embedding for diffusion timesteps.\n",
    "    \n",
    "    This provides a continuous, deterministic embedding for each timestep\n",
    "    using sine and cosine functions at different frequencies.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim=128, max_period=10000):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_period = max_period\n",
    "    \n",
    "    def forward(self, timesteps):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            timesteps: (batch_size,) tensor of timestep indices\n",
    "        \n",
    "        Returns:\n",
    "            (batch_size, embedding_dim) tensor of embeddings\n",
    "        \"\"\"\n",
    "        device = timesteps.device\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        \n",
    "        # Calculate frequency scaling\n",
    "        frequencies = torch.exp(\n",
    "            -math.log(self.max_period) * torch.arange(half_dim, device=device) / half_dim\n",
    "        )\n",
    "        \n",
    "        # Compute arguments: t * frequency\n",
    "        args = timesteps[:, None].float() * frequencies[None, :]\n",
    "        \n",
    "        # Concatenate sin and cos components\n",
    "        embedding = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        \n",
    "        return embedding\n",
    "\n",
    "# Test the time embedding\n",
    "time_embed = SinusoidalTimeEmbedding(embedding_dim=8, max_period=10000)\n",
    "t = torch.tensor([1])\n",
    "embedding = time_embed(t)\n",
    "print(\"Time Embedding for t=1, d=8:\")\n",
    "print(embedding.numpy()[0])\n",
    "print(\"\\nThis matches our theoretical calculation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a312cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with time embedding injection.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "        self.norm1 = nn.GroupNorm(8, out_channels)\n",
    "        self.norm2 = nn.GroupNorm(8, out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.residual_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            self.residual_conv = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, time_emb):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Inject time embedding\n",
    "        time_emb = self.time_mlp(F.relu(time_emb))\n",
    "        x = x + time_emb[:, :, None, None]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x + self.residual_conv(residual)\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Self-attention block for spatial features.\"\"\"\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, 1)\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        residual = x\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = torch.chunk(qkv, 3, dim=1)\n",
    "        \n",
    "        q = q.reshape(B, C, H * W).permute(0, 2, 1)\n",
    "        k = k.reshape(B, C, H * W)\n",
    "        v = v.reshape(B, C, H * W).permute(0, 2, 1)\n",
    "        \n",
    "        attn = torch.bmm(q, k) / math.sqrt(C)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.bmm(attn, v)\n",
    "        out = out.permute(0, 2, 1).reshape(B, C, H, W)\n",
    "        out = self.proj(out)\n",
    "        \n",
    "        return out + residual\n",
    "\n",
    "print(\"✓ UNet building blocks defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c27cb",
   "metadata": {},
   "source": [
    "### 2.3 Complete UNet Architecture\n",
    "\n",
    "The UNet predicts the noise $\\epsilon$ that was added to create the noisy image at timestep $t$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified UNet for CIFAR-10 (32x32 images)\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"Simplified UNet for CIFAR-10 diffusion model.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=3, out_channels=3, time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalTimeEmbedding(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_emb_dim * 4, time_emb_dim * 4)\n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        self.init_conv = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
    "        self.down1 = ResidualBlock(64, 128, time_emb_dim * 4)\n",
    "        self.down2 = ResidualBlock(128, 256, time_emb_dim * 4)\n",
    "        self.downsample1 = nn.Conv2d(128, 128, 3, stride=2, padding=1)\n",
    "        self.downsample2 = nn.Conv2d(256, 256, 3, stride=2, padding=1)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.mid1 = ResidualBlock(256, 256, time_emb_dim * 4)\n",
    "        self.mid_attn = AttentionBlock(256)\n",
    "        self.mid2 = ResidualBlock(256, 256, time_emb_dim * 4)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = ResidualBlock(512, 128, time_emb_dim * 4)  # 256 + 256\n",
    "        self.up2 = ResidualBlock(256, 64, time_emb_dim * 4)   # 128 + 128\n",
    "        self.upsample1 = nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1)\n",
    "        \n",
    "        # Output\n",
    "        self.final_norm = nn.GroupNorm(8, 64)\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, 3, padding=1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)\n",
    "        \n",
    "        # Initial conv\n",
    "        x = self.init_conv(x)\n",
    "        skip0 = x\n",
    "        \n",
    "        # Encoder\n",
    "        x = self.down1(x, t_emb)\n",
    "        skip1 = x\n",
    "        x = self.downsample1(x)\n",
    "        \n",
    "        x = self.down2(x, t_emb)\n",
    "        skip2 = x\n",
    "        x = self.downsample2(x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.mid1(x, t_emb)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid2(x, t_emb)\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.upsample1(x)\n",
    "        x = torch.cat([x, skip2], dim=1)\n",
    "        x = self.up1(x, t_emb)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat([x, skip1], dim=1)\n",
    "        x = self.up2(x, t_emb)\n",
    "        \n",
    "        # Output\n",
    "        x = self.final_norm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test UNet\n",
    "unet = SimpleUNet().to(device)\n",
    "num_params = sum(p.numel() for p in unet.parameters())\n",
    "print(f\"✓ UNet created with {num_params:,} parameters\")\n",
    "\n",
    "# Test forward pass\n",
    "test_x = torch.randn(2, 3, 32, 32).to(device)\n",
    "test_t = torch.tensor([0, 100]).to(device)\n",
    "test_out = unet(test_x, test_t)\n",
    "print(f\"✓ Forward pass successful: {test_x.shape} -> {test_out.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
