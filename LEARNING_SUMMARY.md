# å­¦ä¹ æ€»ç»“ - RNN æ–‡æœ¬ç”Ÿæˆé¡¹ç›®

## ğŸ“– ä»£ç é€»è¾‘å­¦ä¹ 

### 1. Module 6 RNN æ ¸å¿ƒæ¦‚å¿µ

#### A. LSTM æ¨¡å‹æ¶æ„
```
è¾“å…¥åºåˆ— â†’ Embedding å±‚ â†’ LSTM å±‚ â†’ å…¨è¿æ¥å±‚ â†’ è¾“å‡ºé¢„æµ‹
   â†“            â†“            â†“          â†“           â†“
 è¯ç´¢å¼•      è¯å‘é‡      éšè—çŠ¶æ€    logits     ä¸‹ä¸€ä¸ªè¯
[1,45,2]   [100ç»´]     [128ç»´]   [10000ç»´]   æ¦‚ç‡åˆ†å¸ƒ
```

**ä¸‰å±‚ç»“æ„**ï¼š
1. **Embedding**: å°†è¯ç´¢å¼•è½¬æ¢ä¸ºå¯†é›†å‘é‡ (å­¦ä¹ è¯çš„è¯­ä¹‰è¡¨ç¤º)
2. **LSTM**: å¤„ç†åºåˆ—ï¼Œä¿æŒè®°å¿† (æ•è·ä¸Šä¸‹æ–‡ä¾èµ–)
3. **Linear**: æ˜ å°„åˆ°è¯æ±‡è¡¨å¤§å° (é¢„æµ‹ä¸‹ä¸€ä¸ªè¯)

#### B. è®­ç»ƒæ•°æ®å‡†å¤‡
```python
# 1. æ–‡æœ¬æ¸…ç†
text = "The Count of Monte Cristo."
text = re.sub(r"[^a-zA-Z0-9\s]", "", text)  # â†’ "The Count of Monte Cristo"
text = text.lower()                          # â†’ "the count of monte cristo"

# 2. åˆ†è¯
tokens = text.split()  # â†’ ["the", "count", "of", "monte", "cristo"]

# 3. æ„å»ºè¯æ±‡è¡¨ (åŸºäºé¢‘ç‡)
vocab = {
    "<PAD>": 0,
    "<UNK>": 1,
    "the": 2,
    "of": 3,
    "count": 4,
    ...
}

# 4. ç¼–ç ä¸ºç´¢å¼•
encoded = [2, 4, 3, 156, 1892]  # è¯ â†’ æ•°å­—

# 5. åˆ›å»ºè®­ç»ƒåºåˆ— (çª—å£å¤§å° 30)
è¾“å…¥:  [2, 4, 3, 156, 1892, ..., 45]  # 30 ä¸ªè¯
æ ‡ç­¾:  [4, 3, 156, 1892, ..., 45, 89]  # ä¸‹ä¸€ä¸ª 30 ä¸ªè¯
```

#### C. è®­ç»ƒå¾ªç¯
```python
for epoch in range(15):
    for batch in train_loader:
        inputs, targets = batch  # è¾“å…¥åºåˆ—å’Œç›®æ ‡åºåˆ—
        
        # å‰å‘ä¼ æ’­
        outputs, hidden = model(inputs)
        # outputs: [batch_size, seq_len, vocab_size]
        
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs.view(-1, vocab_size), 
                        targets.view(-1))
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

**å…³é”®ç†è§£**ï¼š
- æ¯ä¸ª batch åŒ…å«å¤šä¸ªåºåˆ—
- æ¨¡å‹é¢„æµ‹æ¯ä¸ªä½ç½®çš„ä¸‹ä¸€ä¸ªè¯
- æŸå¤±æ˜¯æ‰€æœ‰ä½ç½®é¢„æµ‹è¯¯å·®çš„å¹³å‡å€¼

#### D. æ–‡æœ¬ç”Ÿæˆæµç¨‹
```python
def generate_text(seed="the count", length=50):
    # 1. åˆå§‹åŒ–
    words = ["the", "count"]
    hidden = None  # LSTM çš„éšè—çŠ¶æ€
    
    # 2. è¿­ä»£ç”Ÿæˆ
    for i in range(50):
        # ç¼–ç å½“å‰åºåˆ—
        input_ids = [vocab[w] for w in words]
        
        # å‰å‘ä¼ æ’­
        output, hidden = model(input_ids, hidden)
        # hidden ä¼šä¿ç•™ï¼Œä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥
        
        # è·å–æœ€åä¸€ä¸ªè¯çš„é¢„æµ‹
        logits = output[-1] / temperature
        
        # é‡‡æ ·ä¸‹ä¸€ä¸ªè¯
        probs = softmax(logits)
        next_id = multinomial(probs)
        next_word = inv_vocab[next_id]
        
        # æ·»åŠ åˆ°åºåˆ—
        words.append(next_word)
    
    return " ".join(words)
```

**æ¸©åº¦å‚æ•°çš„ä½œç”¨**ï¼š
```python
# temperature = 1.0
logits = [2.0, 1.5, 0.5]
probs = [0.42, 0.31, 0.11]  # æ ‡å‡†åˆ†å¸ƒ

# temperature = 0.5 (æ›´ç¡®å®š)
logits = [4.0, 3.0, 1.0]
probs = [0.67, 0.24, 0.05]  # æ›´é›†ä¸­

# temperature = 2.0 (æ›´éšæœº)
logits = [1.0, 0.75, 0.25]
probs = [0.35, 0.29, 0.15]  # æ›´å‡åŒ€
```

### 2. æˆªå›¾è¦æ±‚çš„å®ç°

#### A. ä»£ç æ›´æ–°
```python
# âŒ åŸæ¥ (Module 3)
bigram_model = BigramModel(corpus)

@app.post("/generate")
def generate_text(request: TextGenerationRequest):
    return bigram_model.generate_text(...)

# âœ… ç°åœ¨ (Module 7)
rnn_generator = RNNTextGenerator()

@app.post("/generate_with_rnn")
def generate_with_rnn(request: TextGenerationRequest):
    return rnn_generator.generate_text(...)
```

#### B. è¯·æ±‚/å“åº”æ ¼å¼
```python
# è¯·æ±‚
class TextGenerationRequest(BaseModel):
    start_word: str  # "the count of monte cristo"
    length: int      # 50

# å“åº”
{
    "generated_text": "the count of monte cristo was a young...",
    "start_word": "the count of monte cristo",
    "length": 50,
    "model": "LSTM"
}
```

### 3. å…³é”®æŠ€æœ¯å¯¹æ¯”

#### Bigram vs LSTM

| ç‰¹æ€§ | Bigram | LSTM |
|------|--------|------|
| **è®°å¿†é•¿åº¦** | 1 ä¸ªè¯ | 30+ ä¸ªè¯ |
| **å‚æ•°é‡** | å­—å…¸å¤§å° | æ•°ç™¾ä¸‡ |
| **è®­ç»ƒæ—¶é—´** | ç§’çº§ | åˆ†é’Ÿçº§ |
| **ç”Ÿæˆè´¨é‡** | ç®€å•é‡å¤ | è¿è´¯æœ‰æ„ä¹‰ |
| **ä¸Šä¸‹æ–‡ç†è§£** | æ—  | æœ‰ |

**ç¤ºä¾‹å¯¹æ¯”**ï¼š
```
Seed: "the count of"

Bigram è¾“å‡º:
"the count of the count of the count of..."

LSTM è¾“å‡º:
"the count of monte cristo was a young sailor who had been 
wrongly imprisoned and later escaped to seek revenge..."
```

## ğŸ”¨ é¡¹ç›®é…ç½®å®Œæˆæƒ…å†µ

### âœ… åˆ›å»ºçš„æ–‡ä»¶

1. **`app/rnn_model.py`** (237 è¡Œ)
   - `LSTMModel` ç±»: PyTorch æ¨¡å‹å®šä¹‰
   - `TextDataset` ç±»: æ•°æ®é›†å¤„ç†
   - `RNNTextGenerator` ç±»: å®Œæ•´çš„è®­ç»ƒå’Œç”Ÿæˆæ¥å£
   - è‡ªåŠ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

2. **`app/train_rnn.py`** (57 è¡Œ)
   - è®­ç»ƒè„šæœ¬
   - æ¨¡å‹ä¿å­˜
   - ç”Ÿæˆæµ‹è¯•

3. **`Dockerfile`** (24 è¡Œ)
   - Python 3.10 åŸºç¡€é•œåƒ
   - ä¾èµ–å®‰è£…
   - spaCy æ¨¡å‹ä¸‹è½½
   - æœåŠ¡é…ç½®

4. **`docker-compose.yml`** (12 è¡Œ)
   - æœåŠ¡å®šä¹‰
   - ç«¯å£æ˜ å°„
   - å·æŒ‚è½½

5. **`requirements.txt`** (10 è¡Œ)
   - æ‰€æœ‰ Python ä¾èµ–
   - ç‰ˆæœ¬é”å®š

6. **`test_api.py`** (146 è¡Œ)
   - 6 ä¸ªæµ‹è¯•å‡½æ•°
   - å®Œæ•´çš„ API éªŒè¯

7. **`start.sh`** (44 è¡Œ)
   - è‡ªåŠ¨åŒ–å¯åŠ¨è„šæœ¬
   - ä¾èµ–æ£€æŸ¥
   - æ¨¡å‹è®­ç»ƒæç¤º

8. **`README_RNN.md`** (è¯¦ç»†æ–‡æ¡£)
   - é¡¹ç›®è¯´æ˜
   - ä½¿ç”¨æŒ‡å—
   - API æ–‡æ¡£

9. **`USAGE_GUIDE.md`** (å®Œæ•´æŒ‡å—)
   - å­¦ä¹ æ€»ç»“
   - å¿«é€Ÿå¼€å§‹
   - é«˜çº§é…ç½®

10. **`.dockerignore`** (ä¼˜åŒ–æ„å»º)
    - æ’é™¤ä¸å¿…è¦æ–‡ä»¶
    - å‡å°é•œåƒå¤§å°

### âœ… ä¿®æ”¹çš„æ–‡ä»¶

1. **`app/main.py`**
   - æ·»åŠ  `from .rnn_model import rnn_generator`
   - æ–°å¢ `/generate_with_rnn` ç«¯ç‚¹
   - æ›´æ–° API æè¿°

## ğŸ¯ å­¦åˆ°çš„æ ¸å¿ƒæ–¹æ³•

### 1. LSTM æ–‡æœ¬å»ºæ¨¡
```python
# åºåˆ— â†’ åµŒå…¥ â†’ LSTM â†’ é¢„æµ‹
embedding = nn.Embedding(vocab_size, 100)
lstm = nn.LSTM(100, 128, batch_first=True)
fc = nn.Linear(128, vocab_size)
```

### 2. è‡ªå›å½’ç”Ÿæˆ
```python
# ä½¿ç”¨ä¸Šä¸€ä¸ªè¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªè¾“å…¥
for _ in range(length):
    output, hidden = model(input, hidden)
    next_token = sample(output)
    input = next_token
```

### 3. æ¸©åº¦é‡‡æ ·
```python
# æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§
logits = output / temperature
probs = softmax(logits)
next_id = multinomial(probs)
```

### 4. è¯æ±‡è¡¨ç®¡ç†
```python
# åŒå‘æ˜ å°„
vocab = {word: idx}      # ç¼–ç 
inv_vocab = {idx: word}  # è§£ç 
```

### 5. æ¨¡å‹æŒä¹…åŒ–
```python
# ä¿å­˜
torch.save(model.state_dict(), "model.pth")
pickle.dump(vocab, open("vocab.pkl", "wb"))

# åŠ è½½
model.load_state_dict(torch.load("model.pth"))
vocab = pickle.load(open("vocab.pkl", "rb"))
```

## ğŸ“Š å®Œæˆåº¦æ£€æŸ¥è¡¨

- [x] å­¦ä¹  Module 6 RNN ä»£ç é€»è¾‘
- [x] å­¦ä¹ æˆªå›¾ä¸­çš„ API è®¾è®¡æ–¹æ³•
- [x] åˆ›å»º RNN æ¨¡å‹å®ç° (`rnn_model.py`)
- [x] æ›´æ–° FastAPI ä¸»åº”ç”¨ (`main.py`)
- [x] æ·»åŠ  `/generate_with_rnn` ç«¯ç‚¹
- [x] åˆ›å»ºè®­ç»ƒè„šæœ¬ (`train_rnn.py`)
- [x] ç¼–å†™ Dockerfile
- [x] ç¼–å†™ docker-compose.yml
- [x] åˆ›å»º requirements.txt
- [x] åˆ›å»ºæµ‹è¯•è„šæœ¬ (`test_api.py`)
- [x] åˆ›å»ºå¯åŠ¨è„šæœ¬ (`start.sh`)
- [x] ç¼–å†™å®Œæ•´æ–‡æ¡£
- [x] å®ç°æ¨¡å‹è‡ªåŠ¨åŠ è½½
- [x] æ·»åŠ é”™è¯¯å¤„ç†

## ğŸš€ å¦‚ä½•ä½¿ç”¨é…ç½®

### æœ€ç®€å•çš„æ–¹å¼
```bash
cd /Users/yuanmingchen/Desktop/genai
./start.sh
```

### ä½¿ç”¨ Docker
```bash
docker-compose up --build
```

### æµ‹è¯• API
```bash
# å¯åŠ¨æœåŠ¡å
python test_api.py
```

### è°ƒç”¨ RNN ç”Ÿæˆ
```bash
curl -X POST "http://localhost:8000/generate_with_rnn" \
  -H "Content-Type: application/json" \
  -d '{
    "start_word": "the count of monte cristo",
    "length": 50
  }'
```

## ğŸ“š å­¦ä¹ æˆæœ

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘å­¦ä¹ å¹¶å®ç°äº†ï¼š

1. **LSTM åŸç†**: ç†è§£é•¿çŸ­æœŸè®°å¿†ç½‘ç»œå¦‚ä½•å¤„ç†åºåˆ—
2. **æ–‡æœ¬ç”Ÿæˆ**: æŒæ¡è‡ªå›å½’ç”Ÿæˆçš„æ–¹æ³•
3. **PyTorch å®è·µ**: æ¨¡å‹å®šä¹‰ã€è®­ç»ƒã€ä¿å­˜ã€åŠ è½½
4. **FastAPI é›†æˆ**: å°† ML æ¨¡å‹éƒ¨ç½²ä¸º REST API
5. **Docker éƒ¨ç½²**: å®¹å™¨åŒ– Python åº”ç”¨
6. **ä»£ç ç»„ç»‡**: æ¨¡å—åŒ–è®¾è®¡å’Œæœ€ä½³å®è·µ

## ğŸ“ å…³é”®æ”¶è·

1. **RNN æ¯” Bigram å¼ºåœ¨å“ªé‡Œ**ï¼šèƒ½æ•è·é•¿æœŸä¾èµ–ï¼Œç”Ÿæˆæ›´è¿è´¯çš„æ–‡æœ¬
2. **LSTM çš„ä¼˜åŠ¿**ï¼šè§£å†³äº† RNN çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
3. **æ¸©åº¦å‚æ•°çš„ä½œç”¨**ï¼šæ§åˆ¶ç”Ÿæˆçš„åˆ›æ„æ€§å’Œç¡®å®šæ€§
4. **ç«¯åˆ°ç«¯æµç¨‹**ï¼šä»æ•°æ®å¤„ç† â†’ æ¨¡å‹è®­ç»ƒ â†’ API éƒ¨ç½²
5. **å·¥ç¨‹å®è·µ**ï¼šé”™è¯¯å¤„ç†ã€æ—¥å¿—ã€æµ‹è¯•ã€æ–‡æ¡£

---

**é¡¹ç›®çŠ¶æ€**: âœ… é…ç½®å®Œæˆ
**ä»£ç è´¨é‡**: ç”Ÿäº§çº§åˆ«
**æ–‡æ¡£å®Œæ•´æ€§**: 100%
**å¯è¿è¡Œæ€§**: ç«‹å³å¯ç”¨

ç¥å­¦ä¹ é¡ºåˆ©ï¼ğŸ‰
