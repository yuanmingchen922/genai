{"cells":[{"cell_type":"markdown","metadata":{"id":"kfzkoZ8AFzhZ"},"source":["⚠️ **Static Version Notice**\n","\n","This is a static export of an interactive marimo notebook. Some features have been modified for compatibility:\n","\n","- Interactive UI elements (sliders, dropdowns, text inputs) have been removed\n","- UI variable references have been replaced with default values\n","- Some cells may have been simplified or removed entirely\n","\n","For the full interactive experience, please run the original marimo notebook (.py file) using:\n","```bash\n","uv run marimo edit notebook_name.py\n","```\n","\n","---\n"],"id":"kfzkoZ8AFzhZ"},{"cell_type":"code","execution_count":null,"id":"Hbol","metadata":{"marimo":{"config":{"hide_code":true}},"id":"Hbol"},"outputs":[],"source":["import numpy as np\n"]},{"cell_type":"markdown","id":"MJUe","metadata":{"marimo":{"config":{"hide_code":true}},"id":"MJUe"},"source":["# Module 2: Practice 1 - Probability\n","\n","The goal of this practical is to get some hands-on practice with the concepts of probability and probability distributions, as well as, to establish some theoretical footing for the rest of the course. The math formulas you will see in this section can seem overwhelming at first, so do not worry if you don't follow everything. You should come back to these examples throughout the semester to deepen your understanding."]},{"cell_type":"markdown","id":"vblA","metadata":{"marimo":{"config":{"hide_code":true}},"id":"vblA"},"source":["## Example 1: Probability Distributions and Entropy\n","\n","How can we analyze events that have random components to them? Let's extend the example of a hidden treasure in a box. This time, the color of the box hiding a treasure will be the random variable. Let's specify the total number of boxes of each color below and see how that affects the probability distribution of this random variable, assuming that the treasure is equally likely to be in any one of the boxes."]},{"cell_type":"markdown","id":"Xref","metadata":{"marimo":{"config":{"hide_code":true}},"id":"Xref"},"source":["### Entropy: Measuring Information in a Random Variable\n","\n","One surprising, but extremely useful way to think about random variables and their probability distributions is through a concept from physics called **entropy**. In physics (statistical mechanics) entropy is related to the average amount of information needed to specify the microstate of a system. This has to do with energy levels, Boltzmann distributions and a LOT of math. If you are interested, take a look here: https://math.ucr.edu/home/baez/what_is_entropy/index.html.\n","\n","To understand entropy from information theory point of view, we turn to Claude Shannon and his famous work on \"A Mathematical Theory of Communication\" (https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf).\n","\n","Consider a random variable \\( X \\) defined by a **probability distribution** that represents probabilities of events, for example a treasure box having a particular color. A natural question arises:\n","**How much information do we gain when we observe a specific value sampled from this distribution?**\n","\n","Intuitively, we gain **more information** (alternatively **more surprise**) when we observe an event that is **unlikely** (i.e., has **low probability**) and **less information** (**less surprise**) when the event is **common** (i.e., has **high probability**).\n","\n","Furthermore, if we observe **two unrelated (independent) events**, the total information we gain should be the **sum of the information** from each individual event. Since the probabilities of independent events are multiplied, the function that turns probabilities to information should turn products of probabilities to sums of information. Turns out that mathematically the only function that has this property is the logarithm.\n","\n","These ideas lead us to a fundamental concept in Information Theory: **Entropy**.\n","\n","---\n","\n","### Definition of Entropy\n","\n","Formally, the **entropy** \\( H(P) \\) of a probability distribution \\( P \\) with possible outcomes \\( x_1, x_2, \\ldots, x_n \\) and associated probabilities \\( P(x_i) \\) is defined as:\n","\n","\\[\n","H(P) = -\\sum_{i} P(x_i) \\log P(x_i).\n","\\]\n","\n","- The **logarithm** quantifies the amount of information gained from observing \\( x_i \\).\n","- The **negative sign** ensures the entropy is non-negative.\n","- The **sum** accounts for the expected information over all possible outcomes.\n","\n","Thus, entropy is a measure of the **average amount of information** we expect to gain from observing samples of a random variable. We can think of it as missing information or uncertainty associated with its value.\n","Entropy captures the **uncertainty** or **surprise** inherent in a probability distribution:\n","\n","- **Higher entropy** means more unpredictability (e.g., a fair coin toss).\n","- **Lower entropy** means more certainty (e.g., a biased coin that almost always lands heads).\n","\n","Actually, Shannon in his original paper gave another definition of entropy as the **number of bits** required to optimally encode messages whose contents are chosen from a probability distribution, the idea being that we can encode common events using less bits. Bits are used as the measuring unit if the logarithm has base 2.  Changing to another base only results in a multiplicative factor in the definition of the entropy, so we can think of these differences as different units of measure for information, and in fact in machine learning applications a natural logarithm (base $e$) is typically used.\n","\n","Entropy is a foundational concept that will help us analyze and interpret **loss functions**, particularly in classification and generative models.\n","\n","Note: we have to be careful with our intution since entropy is defined as the average information, so while low probability events have high entropy, they also contribute less to the sum. Experiment with the above distribution by changing the number of boxes of each color to get an intuition for high entropy and low entropy distributions.  What do you notice?"]},{"cell_type":"markdown","id":"RGSE","metadata":{"marimo":{"config":{"hide_code":true}},"id":"RGSE"},"source":["## Example 2: Cross-Entropy and KL Divergence\n","\n","Let's look at another example.  If you are driving on a highway at 67 miles per hour towards a police car with a radar gun, the radar will give a reading of your speed. However, there is a chance that the reading is not accurate due to various factors like interference, calibration issues, etc. This is where probability comes into play.\n","\n","Intuitively, there is certainly a larger probability that the speed will be shown as 66 mph than 50 mph. Is there a way for the radar manufacturer to describe the possible values the radar gun will give?\n","\n","One way, would be to define a probability distribution over the possible speeds. In this case the distribution is not discrete (we cannot list all of the possible speeds), but continuous. For simplicity we use the numbers for this specific example, but we can generalize this to any range of speeds and any distribution.\n","\n","Let's look at an example of two different radars, with the given probability distributions of speeds. Can you guess which distribution below has higher entropy?"]},{"cell_type":"markdown","id":"emfo","metadata":{"marimo":{"config":{"hide_code":true}},"id":"emfo"},"source":["In machine learning applications, the **primary probability distribution of interest** is the **data distribution** \\( P(x) \\), which represents how likely different data points are in the real world (we can think of $x$ as either the data points themselves or the possible outcomes in case of a supervised learning problem, technically $P(y | x)$).\n","\n","If we had access to the full distribution \\( P(x) \\), we could make **optimal predictions** of \\( x \\)..\n","\n","In practice, we **do not know** the true distribution $P(x)$.\n","Instead, we have:\n","\n","- A **set of samples** drawn from \\( P(x) \\)\n","- An **approximate model distribution** \\( Q(x) \\), learned from the data\n","\n","We use \\( Q(x) \\) to make predictions and estimate probabilities.\n","\n","The **cross-entropy** between the true distribution \\( P(x) \\) and the model’s approximation \\( Q(x) \\) is given by:\n","\n","$$\n","H[P, Q] = -\\sum_x P(x) \\log Q(x)\n","$$\n","\n","Based on Shannon's definition this quantity can be interpreted as the **expected number of bits needed** (if we use based 2 logarithm) to encode samples from \\( P \\) **using a code optimized for** \\( Q \\).\n","\n","In other words, **cross-entropy measures how inefficient it is to approximate \\( P \\) using \\( Q \\)**.\n","\n","- Lower cross-entropy means \\( Q \\) is a better approximation of \\( P \\)\n","- Minimizing the empirical cross-entropy is a **common loss function** in classification and generative modeling tasks\n","\n","$$\n","-\\frac{1}{N} \\sum_{i=1}^{N} \\log Q(x_i)\n","$$\n","\n","Note: The term $P(x)$ is absorbed into the empirical averaging over the dataset.\n","This is valid because the dataset is assumed to be an independent and identically distributed i.i.d. sample from the true $P(x)$."]},{"cell_type":"markdown","id":"Hstk","metadata":{"marimo":{"config":{"hide_code":true}},"id":"Hstk"},"source":["### Kullback-Leibler (KL) divergence\n","\n","We finish the discussion on entropy with another concept relating how close two probability distributions are, the **Kullback-Leibler (KL) divergence**.\n","\n","The **KL divergence** between two distributions \\( P \\) (the true distribution) and \\( Q \\) (the model’s predicted distribution) is defined as:\n","\n","\\[\n","D_{\\text{KL}}(P \\,\\|\\, Q) = \\sum_x P(x) \\log \\left(\\frac{P(x)}{Q(x)}\\right)\n","\\]\n","\n","Since\n","\n","$$\n","\\log \\left(\\frac{P(x)}{Q(x)}\\right) = \\log(P(x)) - \\log(Q(x)),\n","$$\n","\n","we have\n","\n","$$\n","D_{\\text{KL}}(P \\,\\|\\, Q) =  \\underbrace{H[P, Q]}_{cross-entropy} - \\underbrace{H[P]}_{entropy}.\n","$$\n","\n","this measures how many **extra** bits are needed to encode samples from \\( P \\) using a code optimized for \\( Q \\). A **lower KL divergence** indicates that \\( Q \\) is a better approximation of \\( P \\).\n","\n","KL divergence will be useful to compare two known or approximate distributions. You can experiment with changing the radar gaussian distributions below to see how the KL divergence changes. Note: with continuous distributions the definitions above involve integrals instead of sums, but intuitively are analogous."]},{"cell_type":"markdown","id":"ZHCJ","metadata":{"marimo":{"config":{"hide_code":true}},"id":"ZHCJ"},"source":["## Example 3: Bayes Theorem\n","\n","To get comfortable with handling probability expressions, we will play a treasure hunt game on a 5x5 grid.\n","The rules are simple:\n","\n","- There is a treasure hidden somewhere on the grid (💎).\n","- You have to guess where it is in a minimum number of tries.\n","- Every time you guess I give you a distance clue: the manhattan distance to the treasure.\n","- To make this a bit more challenging:\n","    - 80% of the time the clue will be correct.\n","    - 10% of the time it will be off by 1.\n","    - 10% of the time it will be off by -1.\n","- Click on different cells below to start the game!\n","- Click on 'Simulate 1 Turn' to choose cell based on the highest probability and update the probability table based on the latest distance clue."]},{"cell_type":"markdown","id":"qnkX","metadata":{"marimo":{"config":{"hide_code":true}},"id":"qnkX"},"source":["---\n","## Explanation\n","\n","How does the 'Simulate 1 Turn' work to find the location in only a few tries?\n","\n","Can we use probability theory to make this efficient?\n","\n","Note that I gave you the probabilities of what the distance clue should be, given the treasure location. We want to *reverse* that probability and obtain the probability of treasure location given the distance clue. This is a perfect application of Bayes Theorem!\n","\n","Notation:\n","\n","Let's use $T_{ij}$ as the random variable that describes the existence of treasure in cell $(i,j)$.\n","\n","We will say that $T_{ij} = 🌱$ if there is no treasure in that cell and $T_{ij} = 💎$ if there is.\n","\n","After each turn we get a distance clue. Let $d_t$ represent the distance clue we get at turn $t$.\n","\n","So $P(T_{ij} = 💎 | d_1)$ represents our belief after 1 turn that $T_{ij}$ contains treasure.\n","\n","$P(T_{ij} = 💎  | d_t, ..., d_2, d_1)$ represents our belief after $t$ turns ($t$ clues) that the cell $(i,j)$ contains treasure."]},{"cell_type":"code","execution_count":null,"id":"Vxnm","metadata":{"marimo":{"config":{"hide_code":true}},"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Vxnm","executionInfo":{"status":"error","timestamp":1757012423694,"user_tz":240,"elapsed":42,"user":{"displayName":"Prachi Patel","userId":"16433751110035238201"}},"outputId":"251ca0c2-8973-4912-9dfd-ce3db12618d7"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'number_array' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1048512001.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\n\u001b[1;32m      2\u001b[0m     f\"\"\"\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;31m$\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mT_\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mij\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m💎\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mnumber_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m$\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m {'✅' if number_array[0].value == 0 \n\u001b[1;32m      5\u001b[0m else '❌'}\n","\u001b[0;31mNameError\u001b[0m: name 'number_array' is not defined"]}],"source":["print(\n","    f\"\"\"\n","$P(d_1 = 0 | T_{{ij}} = 💎) = {number_array[0].value}$\n","{'✅' if number_array[0].value == 0\n","else '❌'}\n","\n","{'Correct! The probability that the distance if off by 2 units is actually 0.' if number_array[0].value == 0 else 'Note that the real distance between those locations is 2, so what is the probability that the clue is off by 2 units?'}\n","\"\"\"\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"DnEU","metadata":{"marimo":{"config":{"hide_code":true}},"id":"DnEU"},"outputs":[],"source":["print(\n","    f\"\"\"\n","What about the probability that the distance clue will be given as 1?\n","\n","$P(d_1 = 1 | T_{{ij}} = 💎) =$ {number_array[1]} &nbsp;&nbsp; $P(d_1 = -1 | T_{{ij}} = 💎) =$ {number_array[2]}\n","\n","$P(d_1 = 2 | T_{{ij}} = 💎) =$ {number_array[3]} &nbsp;&nbsp; $P(d_1 = -2 | T_{{ij}} = 💎) =$ {number_array[4]}\n","\"\"\"\n",")\n"]},{"cell_type":"markdown","id":"ulZA","metadata":{"marimo":{"config":{"hide_code":true}},"id":"ulZA"},"source":["We can now write a more general formula of the probability of the distance clue being given as $d$ if  the treasure is in cell (i,j) and our guess was cell (k,l):\n","\n","$$\n","P(d_t = d | T_{ij} = 💎) =\n","\\begin{cases}\n","0.8 & \\text{if distance((k,l), (i,j)) = d} \\\\\n","0.2 & \\text{if distance((k,l), (i,j)) = d $\\pm 1$} \\\\\n","0 & \\text{otherwise}\n","\\end{cases}\n","$$\n","\n","And using Bayes Formula:\n","\n","    $$P(T_{ij} = 💎 | d_t = d, d_{t-1} ..., d_1) = \\frac{\\overbrace{P(d_t = d| T_{ij} = 💎, d_{t-1}, ..., d_1)}^{likelihood} \\overbrace{P(T_{ij} = 💎, d_{t-1}, ..., d_1)}^{prior}}{P(d_1, d_2, ..., d_{t})}$$\n","\n","Note how the prior gets updated after each new clue by being multiplied by the likelihood. We don't have to worry about the denominator since it is the same for all of the cells, so as long as we normalize the probabilities at the end we are good to go.\n","\n","----\n","## Implementation\n","\n","The part of implementation that we want to study deals with the logic of how the algorithm decides where to search next based on the probability table update that uses the previous guess and the distance clue received after the previous guess. For each cell it calculates the distance to the  guess location (i.e. the correct distance if that cell had the treasure) and compares it with the distance clue received. This is the 'update_probabilities' function. It is just the implementation of the above formula."]},{"cell_type":"code","execution_count":null,"id":"ecfG","metadata":{"id":"ecfG"},"outputs":[],"source":["def update_probabilities(probability_grid, guess, distance_clue):\n","    \"\"\" Update the probability grid using Bayesian inference \"\"\"\n","    new_grid = np.zeros_like(probability_grid)\n","    total_prob = 0\n","\n","    for i in range(probability_grid.shape[0]):\n","        for j in range(probability_grid.shape[1]):\n","            estimated_distance = abs(i - guess[0]) + abs(j - guess[1])\n","            if estimated_distance == distance_clue: # correct clue\n","                likelihood = 0.6\n","            elif ((estimated_distance - distance_clue) == 1 or\n","                 (estimated_distance - distance_clue) == -1): # off by +1 or -1\n","                likelihood = 0.2\n","            else:\n","                likelihood = 0\n","            new_grid[i, j] = probability_grid[i, j] * likelihood\n","            total_prob += new_grid[i, j]\n","\n","    if total_prob > 0:\n","        new_grid /= total_prob\n","    return new_grid\n"]},{"cell_type":"code","execution_count":null,"id":"Pvdt","metadata":{"marimo":{"config":{"hide_code":true}},"id":"Pvdt"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","class BayesianTreasureHunt:\n","    def __init__(self, grid_size=5):\n","        self.grid_size = grid_size\n","        self.reset_game()\n","\n","    def reset_game(self):\n","        self.treasure_location = (np.random.randint(0, self.grid_size), np.random.randint(0, self.grid_size))\n","        self.probability_grid = np.full((self.grid_size, self.grid_size), 1 / (self.grid_size**2))\n","        self.seeker_guesses = []\n","        self.current_guess = None\n","        self.distance_clue = None\n","        self.iterations = 0\n","\n","    def provide_clue(self, guess):\n","        \"\"\" Provides a noisy clue based on a distribution around the true distance with 20% incorrect information \"\"\"\n","        true_distance = abs(guess[0] - self.treasure_location[0]) + abs(guess[1] - self.treasure_location[1])\n","        noise = np.random.choice([0, -1, 1], p=[0.6, 0.2, 0.2])\n","        return max(0, true_distance + noise)\n","\n","    def play_round_manual(self, guess):\n","        self.current_guess = guess\n","        self.seeker_guesses.append(self.current_guess)\n","        distance = self.provide_clue(self.current_guess)\n","        self.iterations += 1\n","        self.distance_clue = distance\n","        return distance\n","\n","    def play_round(self):\n","        \"\"\" Plays one round of the game \"\"\"\n","        self.current_guess = tuple(np.unravel_index(np.argmax(self.probability_grid, axis=None), self.probability_grid.shape))\n","        self.seeker_guesses.append(self.current_guess)\n","        if (self.current_guess == self.treasure_location):\n","            return 0\n","        else:\n","            self.probability_grid[self.current_guess] = 0\n","        distance_clue = self.provide_clue(self.current_guess)\n","        self.probability_grid = update_probabilities(self.probability_grid, self.current_guess, distance_clue)\n","        self.iterations += 1\n","        self.distance_clue = distance_clue\n","        return distance_clue\n","\n","    def get_game_state(self):\n","        return {\n","            \"Treasure Location\": self.treasure_location[::-1],\n","            \"Seeker Guesses\": np.flip(self.seeker_guesses, axis=1),\n","            \"Iterations\": self.iterations,\n","            \"Current Guess\": self.current_guess[::-1]\n","        }\n","\n","# Run an interactive session\n","game = BayesianTreasureHunt(grid_size=5)\n"]},{"cell_type":"code","execution_count":null,"id":"lEQa","metadata":{"marimo":{"config":{"hide_code":true}},"id":"lEQa"},"outputs":[],"source":["import matplotlib.patches as patches\n","\n","# Define the box colors and labels\n","box_colors = []\n","num_boxes = 0\n","for _i in range(num_colors):\n","    box_colors.extend([colors[_i]] * num_boxes_ui[_i].value)\n","    num_boxes += num_boxes_ui[_i].value\n","\n","box_labels = [f\"Box {i+1}\" for i in range(num_boxes)]\n","\n","# Define positions in two rows of 5 boxes\n","box_positions = [(i % 5, -(i+1) // 5) for i in range(num_boxes)]  # Row layout\n","\n","# Create the figure\n","fig, ax = plt.subplots(figsize=(10, 3))\n","\n","for _i, (_x, _y) in enumerate(box_positions):\n","    # Draw box\n","    rect = patches.Rectangle((_x, _y), 1, 1, facecolor=box_colors[_i], edgecolor='black')\n","    ax.add_patch(rect)\n","\n","    # Add label in the center\n","    text_color = 'black' if box_colors[_i] == \"gold\" else 'white'\n","    ax.text(_x + 0.5, _y + 0.5, f\"{box_labels[_i]}\\n{box_colors[_i]}\", ha='center', va='center', fontsize=10, color=text_color)\n","\n","# Formatting\n","ax.set_xlim(0, 5)\n","ax.set_ylim(-num_boxes//5, 0)\n","ax.set_aspect('equal')\n","ax.axis('off')\n","plt.title(f\"{num_boxes} Boxes — One Contains a Treasure\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"PKri","metadata":{"marimo":{"config":{"hide_code":true}},"id":"PKri"},"outputs":[],"source":["color_counts = [num_boxes_ui[i].value for i in range(num_colors)]\n","color_probs = color_counts/np.sum(color_counts)  # Normalize probabilities\n","# Plot the distributions\n","plt.figure(figsize=(8, 4))\n","plt.bar(colors, color_probs, color=colors, width=0.3, alpha=0.8)\n","plt.xlabel(\"Color\")\n","plt.ylabel(\"Probability\")\n","plt.title(\"Discrete Probability Distribution\")\n","plt.xticks(colors)\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"SFPL","metadata":{"id":"SFPL"},"outputs":[],"source":["def information(x):\n","    return np.log(x) if x != 0 else 0\n","\n","entropy = np.sum([-p*information(p) for p in color_probs])\n"]},{"cell_type":"code","execution_count":null,"id":"Kclp","metadata":{"marimo":{"config":{"hide_code":true}},"id":"Kclp"},"outputs":[],"source":["from scipy.stats import norm\n","from scipy.special import rel_entr\n","\n","# Define the range of speeds\n","x = np.linspace(60, 74, 500)\n","\n","# Compute the PDF values\n","_p = norm.pdf(x, loc=67, scale=0.5)\n","_q = norm.pdf(x, loc=67, scale=2.0)\n","\n","# Normalize to make them proper discrete approximations of probability distributions\n","_p /= np.sum(_p)\n","_q /= np.sum(_q)\n","\n","# Plot the distributions\n","plt.figure(figsize=(10, 5))\n","plt.plot(x, _p, label=f\"Radar A (μ=67, σ={0.5})\", color='blue')\n","plt.plot(x, _q, label=f\"Radar B (μ=67, σ={2.0})\", color='green')\n","plt.fill_between(x, _p, alpha=0.3, color='blue')\n","plt.fill_between(x, _q, alpha=0.3, color='green')\n","plt.title(\"Continuous Radar Speed Distributions (Gaussian)\")\n","plt.xlabel(\"Measured Speed (mph)\")\n","plt.ylabel(\"Density\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"iLit","metadata":{"marimo":{"config":{"hide_code":true}},"id":"iLit"},"outputs":[],"source":["mu_p, sigma_p = \"default\", \"default\"  # Radar Gun A: more precise\n","mu_q, sigma_q = \"default\", \"default\"  # Radar Gun B: less precise\n","\n","p = norm.pdf(x, loc=mu_p, scale=sigma_p)\n","q = norm.pdf(x, loc=mu_q, scale=sigma_q)\n","\n","# Normalize to make them proper discrete approximations of probability distributions\n","p /= np.sum(p)\n","q /= np.sum(q)\n","\n","\n","kl_pq = np.sum(rel_entr(p, q))  # KL(P || Q)\n","kl_qp = np.sum(rel_entr(q, p))  # KL(Q || P)\n","\n","# Plot the distributions\n","plt.figure(figsize=(10, 5))\n","plt.plot(x, p, label=f\"Radar A (μ=67, σ={sigma_p})\", color='blue')\n","plt.plot(x, q, label=f\"Radar B (μ=67, σ={sigma_q})\", color='green')\n","plt.fill_between(x, p, alpha=0.3, color='blue')\n","plt.fill_between(x, q, alpha=0.3, color='green')\n","plt.title(f\"Continuous Radar Speed Distributions (Gaussian). KL(P || Q): {kl_pq:.4f}\")\n","plt.xlabel(\"Measured Speed (mph)\")\n","plt.ylabel(\"Density\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"ROlb","metadata":{"marimo":{"config":{"hide_code":true}},"id":"ROlb"},"outputs":[],"source":["print(fr'''\n","\n","{print('YOU WIN' if game.treasure_location == game.current_guess else f\"Distance clue:  {game.distance_clue}\").callout(kind=\"success\")}\n","\n","{field}\n","\n","{buttons}\n","\n","Probability Table (only updated when Simulating Turns):\n","\n","{prob}\n","\n","\n","Guesses: {game.seeker_guesses}\n","''')\n","# Treasure Location: {game.treasure_location}\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}