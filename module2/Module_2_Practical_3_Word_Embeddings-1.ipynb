{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Module 2: Practice 3 - Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['bash', '-c', 'uv run python -m spacy download en_core_web_lg'], capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, we import the *spacy* library and load the large English model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Next, let's define a function to calculate word embeddings based on an input word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding(input_word):\n",
    "    word = nlp(input_word)\n",
    "    return word.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Let's try with the word 'apple'.  For brevity, only the first elements of the embedding vector are displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_embedding(\"apple\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "word_input_ui = mo.ui.text(value=\"orange\")\n",
    "mo.md(f'''\n",
    "## More Practice with Word Embeddings\n",
    "\n",
    "Type in a word to generate an embedding vector: {word_input_ui}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "word_embedding = calculate_embedding(word_input_ui.value)\n",
    "word_embedding[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Similarity\n",
    "Let's add a function to calculate the similarity between two words based on their embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(word1, word2):\n",
    "    return nlp(word1).similarity(nlp(word2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Compare embeddings of words: 'apple' and 'car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_similarity(\"apple\", \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "word1_input_ui = mo.ui.text(value=\"apple\")\n",
    "word2_input_ui = mo.ui.text(value=\"orange\")\n",
    "mo.md(f'''\n",
    "## More Practice with Similarity\n",
    "\n",
    "Enter any two words to generate the similarity measure between them: \n",
    "\n",
    "Word 1: {word1_input_ui} &nbsp; Word 2: {word2_input_ui}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "calculate_similarity(word1_input_ui.value, word2_input_ui.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "la_word1_input_ui = mo.ui.text(value='spain')\n",
    "la_word2_input_ui = mo.ui.text(value='paris')\n",
    "la_word3_input_ui = mo.ui.text(value='france')\n",
    "la_word4_input_ui = mo.ui.text(value='madrid')\n",
    "\n",
    "mo.md(f'''\n",
    "We can even do linear algebra with the underlying vector representations. Enter any three words and calculate similarity with a fourth one, e.g.:\n",
    "\n",
    "'woman' + 'king' - 'man' with 'queen'\n",
    "\n",
    "OR\n",
    "\n",
    "'spain' + 'paris' - 'france' with 'madrid': \n",
    "\n",
    "Word 1: {la_word1_input_ui} + (Word 2: {la_word2_input_ui} - Word 3: {la_word3_input_ui})\n",
    "\n",
    "compared to\n",
    "\n",
    "Word 4: {la_word4_input_ui}.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "la_word1_embedding = nlp(la_word1_input_ui.value).vector\n",
    "la_word2_embedding = nlp(la_word2_input_ui.value).vector\n",
    "la_word3_embedding = nlp(la_word3_input_ui.value).vector\n",
    "la_word = la_word1_embedding + (la_word2_embedding - la_word3_embedding)\n",
    "la_word4 = nlp(la_word4_input_ui.value).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"Cosine similarity: \", cosine_similarity([la_word], [la_word4])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "----\n",
    "## Sentence Embeddings\n",
    "\n",
    "Finally, to calculate an embedding for a sentence, we can just average the embeddings of all the words in that sentence.  We will again use `spacy` to calculate the sentence embeddings.\n",
    "\n",
    "```python\n",
    "query = \"What is the capital of France?\"\n",
    "info_1 = \"The capital of France is Paris\"\n",
    "info_2 = \"France is a beautiful country\"\n",
    "info_3 = \"Today is very warm in New York City\"\n",
    "print(\"Response 1 Similarity: \", nlp(query).similarity(nlp(info_1)))\n",
    "print(\"Response 2 Similarity: \", nlp(query).similarity(nlp(info_2)))\n",
    "print(\"Response 3 Similarity: \", nlp(query).similarity(nlp(info_3)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "query = \"What is the capital of France?\"\n",
    "info_1 = \"The capital of France is Paris\"\n",
    "info_2 = \"France is a beautiful country\"\n",
    "info_3 = \"Today is very warm in New York City\"\n",
    "print(\"Response 1 Similarity: \", nlp(query).similarity(nlp(info_1)))\n",
    "print(\"Response 2 Similarity: \", nlp(query).similarity(nlp(info_2)))\n",
    "print(\"Response 3 Similarity: \", nlp(query).similarity(nlp(info_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "Being able to quickly calculate similarities between a query and target information text is very powerful for Information Retrieval, especially when combined with Large Language Models trained for chat/question answering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
