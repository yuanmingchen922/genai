# RNN 文本生成系统架构图

## 1. 系统整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                        用户/客户端                           │
│                    (Browser/curl/App)                       │
└─────────────────────────┬───────────────────────────────────┘
                          │ HTTP Request
                          ▼
┌─────────────────────────────────────────────────────────────┐
│                      FastAPI 服务器                          │
│                    (app/main.py:8000)                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  端点路由:                                           │   │
│  │  - GET  /              → 首页                       │   │
│  │  - POST /generate      → Bigram 生成                │   │
│  │  - POST /generate_with_rnn → RNN 生成 ⭐            │   │
│  │  - POST /embedding     → 词嵌入                     │   │
│  │  - POST /similarity    → 词相似度                   │   │
│  │  - POST /classify-image → 图像分类                  │   │
│  └─────────────────────────────────────────────────────┘   │
└───────┬─────────────────┬─────────────────┬─────────────────┘
        │                 │                 │
        ▼                 ▼                 ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│ bigram_model │  │  rnn_model   │  │cnn_classifier│
│    .py       │  │    .py ⭐    │  │    .py       │
└──────────────┘  └──────────────┘  └──────────────┘
```

## 2. RNN 模型内部结构

```
┌─────────────────────────────────────────────────────────────┐
│              RNNTextGenerator 类                             │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌────────────────────────────────────────────────┐         │
│  │ 1. 初始化 (__init__)                            │         │
│  │    - 加载预训练模型 (如果存在)                  │         │
│  │    - 否则创建空模型                             │         │
│  └────────────────────────────────────────────────┘         │
│                      ↓                                       │
│  ┌────────────────────────────────────────────────┐         │
│  │ 2. 训练 (train_from_text)                       │         │
│  │    ① 下载文本 (基督山伯爵)                      │         │
│  │    ② 预处理 (清理、分词)                        │         │
│  │    ③ 构建词汇表 (10000 词)                      │         │
│  │    ④ 编码序列                                   │         │
│  │    ⑤ LSTM 训练 (15 epochs)                      │         │
│  └────────────────────────────────────────────────┘         │
│                      ↓                                       │
│  ┌────────────────────────────────────────────────┐         │
│  │ 3. 生成 (generate_text)                         │         │
│  │    ① 编码种子文本                               │         │
│  │    ② LSTM 前向传播                              │         │
│  │    ③ 温度采样                                   │         │
│  │    ④ 解码为文本                                 │         │
│  └────────────────────────────────────────────────┘         │
│                      ↓                                       │
│  ┌────────────────────────────────────────────────┐         │
│  │ 4. 持久化 (save_model / load_model)             │         │
│  │    - 保存: model.pth + vocab.pkl                │         │
│  │    - 加载: 恢复模型和词汇表                     │         │
│  └────────────────────────────────────────────────┘         │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

## 3. LSTM 模型架构

```
输入序列: ["the", "count", "of", "monte", "cristo"]
    ↓
┌─────────────────────────────────────────────────────────────┐
│  词索引编码: [2, 45, 3, 156, 892]                            │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│  Embedding 层 (vocab_size=10000 → embedding_dim=100)        │
│  [2, 45, 3, 156, 892] → [[0.2, -0.1, ...], [...], ...]     │
│  输出: [batch, seq_len, 100]                                │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│  LSTM 层 (embedding_dim=100 → hidden_dim=128)               │
│  ┌───────┐  ┌───────┐  ┌───────┐  ┌───────┐  ┌───────┐   │
│  │ Cell  │→│ Cell  │→│ Cell  │→│ Cell  │→│ Cell  │   │
│  │  t=1  │  │  t=2  │  │  t=3  │  │  t=4  │  │  t=5  │   │
│  └───────┘  └───────┘  └───────┘  └───────┘  └───────┘   │
│     ↓          ↓          ↓          ↓          ↓         │
│  hidden    hidden    hidden    hidden    hidden           │
│  输出: [batch, seq_len, 128]                               │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│  全连接层 (hidden_dim=128 → vocab_size=10000)               │
│  每个位置预测下一个词的概率分布                              │
│  输出: [batch, seq_len, 10000]                              │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│  Softmax + 采样                                              │
│  选择概率最高的词 (或温度采样)                               │
│  输出: 下一个词的索引                                        │
└─────────────────────────────────────────────────────────────┘
    ↓
解码: 索引 → 词 → 文本
```

## 4. 文本生成流程

```
开始: seed_text = "the count of monte cristo"
│
├─ 步骤 1: 编码
│  words = ["the", "count", "of", "monte", "cristo"]
│  input_ids = [2, 45, 3, 156, 892]
│  hidden = None
│
├─ 步骤 2: 循环生成 (50 次)
│  │
│  ├─ 迭代 1:
│  │  ① output, hidden = model([2,45,3,156,892], None)
│  │  ② logits = output[-1] / temperature
│  │  ③ probs = softmax(logits)
│  │  ④ next_id = sample(probs)  → 假设 = 1234 (词 "was")
│  │  ⑤ words.append("was")
│  │  ⑥ input_ids.append(1234)
│  │
│  ├─ 迭代 2:
│  │  ① output, hidden = model([2,45,...,1234], hidden)
│  │  ② ... (重复)
│  │  ④ next_id = 567 (词 "a")
│  │  ⑤ words.append("a")
│  │
│  └─ ... 重复 50 次
│
└─ 步骤 3: 拼接输出
   结果: "the count of monte cristo was a young sailor who..."
```

## 5. API 请求响应流程

```
客户端                      FastAPI                    RNN 模型
  │                           │                           │
  │  POST /generate_with_rnn  │                           │
  │  {                        │                           │
  │    "start_word": "the",   │                           │
  │    "length": 50           │                           │
  │  }                        │                           │
  ├─────────────────────────→ │                           │
  │                           │                           │
  │                           │ generate_text(            │
  │                           │   "the", 50               │
  │                           │ )                         │
  │                           ├─────────────────────────→ │
  │                           │                           │
  │                           │                      ① 编码种子
  │                           │                      ② LSTM 推理
  │                           │                      ③ 采样生成
  │                           │                      ④ 解码文本
  │                           │                           │
  │                           │  "the count of..."        │
  │                           │ ←─────────────────────────┤
  │                           │                           │
  │  {                        │                           │
  │    "generated_text": "...",                          │
  │    "model": "LSTM"        │                           │
  │  }                        │                           │
  │ ←─────────────────────────┤                           │
  │                           │                           │
```

## 6. 训练流程

```
开始训练
│
├─ 步骤 1: 数据准备
│  ├─ 下载文本
│  │  URL: gutenberg.org → "The Count of Monte Cristo"
│  │
│  ├─ 预处理
│  │  原文: "The Count of Monte-Cristo!!"
│  │  清理: "the count of monte cristo"
│  │
│  ├─ 分词
│  │  ["the", "count", "of", "monte", "cristo", ...]
│  │
│  ├─ 构建词汇表
│  │  Counter → 取前 9998 个高频词
│  │  {
│  │    "<PAD>": 0,
│  │    "<UNK>": 1,
│  │    "the": 2,
│  │    "of": 3,
│  │    ...
│  │  }
│  │
│  └─ 编码
│     [2, 45, 3, 156, ...]
│
├─ 步骤 2: 创建数据集
│  窗口大小: 30
│  输入:  [w0, w1, w2, ..., w29]
│  标签:  [w1, w2, w3, ..., w30]
│
├─ 步骤 3: 训练循环
│  for epoch in 1..15:
│    for batch in train_loader:
│      ① 前向传播: outputs = model(inputs)
│      ② 计算损失: loss = CrossEntropy(outputs, targets)
│      ③ 反向传播: loss.backward()
│      ④ 更新权重: optimizer.step()
│
└─ 步骤 4: 保存模型
   ├─ model.pth (模型权重)
   └─ vocab.pkl (词汇表)
```

## 7. Docker 部署架构

```
┌───────────────────────────────────────────────────────┐
│                    Docker Host                        │
│                                                        │
│  ┌──────────────────────────────────────────────┐    │
│  │        genai-api Container                   │    │
│  │                                               │    │
│  │  ┌─────────────────────────────────────┐     │    │
│  │  │   Python 3.10 环境                  │     │    │
│  │  │   - FastAPI                         │     │    │
│  │  │   - PyTorch                         │     │    │
│  │  │   - spaCy (en_core_web_lg)          │     │    │
│  │  └─────────────────────────────────────┘     │    │
│  │                                               │    │
│  │  ┌─────────────────────────────────────┐     │    │
│  │  │   应用代码                          │     │    │
│  │  │   /app/main.py                      │     │    │
│  │  │   /app/rnn_model.py                 │     │    │
│  │  │   /app/...                          │     │    │
│  │  └─────────────────────────────────────┘     │    │
│  │                                               │    │
│  │  ┌─────────────────────────────────────┐     │    │
│  │  │   模型文件 (挂载卷)                 │     │    │
│  │  │   /app/models/                      │     │    │
│  │  │   - cnn_classifier.pth              │     │    │
│  │  │   - rnn_text_generator.pth          │     │    │
│  │  │   - rnn_vocab.pkl                   │     │    │
│  │  └─────────────────────────────────────┘     │    │
│  │                                               │    │
│  │  Port 8000 (uvicorn)                         │    │
│  └──────────────────┬────────────────────────────┘    │
│                     │                                 │
│                     │ Port Mapping 8000:8000          │
└─────────────────────┼─────────────────────────────────┘
                      │
                      ▼
              Host: localhost:8000
              Client 访问
```

## 8. 文件依赖关系

```
main.py
├── imports bigram_model.py
│   ├── BigramModel
│   └── WordEmbeddingModel (spaCy)
│
├── imports rnn_model.py ⭐
│   ├── LSTMModel (PyTorch)
│   ├── TextDataset
│   └── RNNTextGenerator
│       ├── 依赖 torch
│       ├── 依赖 requests
│       └── 生成: models/rnn_text_generator.pth
│
└── imports cnn_classifier.py
    └── CNNClassifier (PyTorch)

train_rnn.py
└── imports rnn_model.py
    └── 训练并保存模型

test_api.py
└── 调用 main.py 的 API 端点

Dockerfile
├── 基于 python:3.10-slim
├── 安装 requirements.txt
├── 下载 en_core_web_lg
└── 启动 uvicorn

docker-compose.yml
└── 编排 genai-api 服务
```

---

这个架构图展示了整个 RNN 文本生成系统的完整结构和数据流。
